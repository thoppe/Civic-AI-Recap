I hereby call the March 2023 meeting of the State Board of Education to order at one o'clock
p.m.
That's very loud.
And I'd like us to start by saluting the flag.
Senator Rodriguez, will you please lead us in the Pledge of Allegiance?
Absolutely.
Please stand.
Place your hand on your plate.
Then you begin.
I pledge allegiance to the flag of the United States of America and to the republic for
which it stands.
The United States of America, commonly known as the United States of America, is a country
primarily located in the United States of America.
We had Siri doing the pledge with us.
So this is good because part of the idea for today was that we were going to be very informal
and have this informal retreat.
That was before we talked to the lawyers and figured out that we needed to be able to broadcast
and organize.
And I want to thank all the staff who took this idea and made it come true.
But I do want you to try to feel as informal as you can.
And maybe we'll have Siri interrupt us again.
Item one is the study session on assessment innovation.
And our goal is to really look at assessment that can support teaching and learning and
think about together how we can imagine our system so that it does that.
And I have a couple of remarks, which I literally put on the back of a napkin, that I want to
just kind of help us get our heads wrapped around this.
We are coming out of a pandemic and we have an opportunity, we have an obligation to figure
out how to help accelerate learning for all of our students and to heighten equity for
all of them, especially those who have been furthest from opportunity.
There's a nationwide conversation going on about that.
And more than 20 states now are rethinking their teaching, learning and assessment systems
to try to create an integrated approach that provides information about the learning process
that can feed into supports for students.
Many of them are looking at how to deepen the opportunities for performance assessment
where students get to show what they know in ways that are more than selecting an answer
from a set of predetermined answers.
The college board has also announced just recently that they're going to be putting
performance assessments into each of their courses.
So some of you may know that they started, of course, the art course and the language courses
have had such assessments for a long time.
They recently put together a research and inquiry series of courses where students are
engaged in inquiry and projects and those are designed and scored both by other AP teachers
and sometimes by their teacher.
And then they put in place a performance task in the computer science AP course which requires
that students design a program and collaboratively and test it out and then individually
describe and explain what they've done.
And what they found is that in the course of doing this, they're not only getting a broader
and more diverse group of students into the courses, they're succeeding at higher rates,
equity is increasing and the studies show that the students who have that experience
do better in college.
So some folks have had this experience in various ways but this is the nature of the conversation
that is going on and teachers, when that happens, have ways to see what their students are
thinking and what they're learning along the way before the end of the year.
This is very much like what a lot of other countries do.
If you were in the UK or Australia or Singapore or New Zealand, that kind of element of performance
would be part of the examination system and would be not just at the end of the year but
would be part of the process of teaching and learning.
So the conversation has been about assessment of as and for learning.
The US has more of a tradition of assessment of learning but when assessment is for learning,
it provides deeper information than a score alone and it also can emulate what good learning
and teaching looks like.
The US Department of Education is re-regulating the Innovative Authority for Innovative Assessment
Demonstration Authority this spring to enable more states to be able to take up innovations
and assessment because of the drumbeat that came about during the pandemic for more opportunity.
And they have also begun to redesign the guidance that they give to states.
So there's a lot happening.
We are fortunate to already be using one of the more innovative assessments in the country
through Smarter Balanced, through the consortium of states that develop Smarter Balanced.
It includes some performance tasks.
It was because of the design of the rules at the time, sort of at the end of the year,
but you've heard from Tony Alpert, the director of Smarter Balanced, in our last meeting about
pilots to potentially locate performance assessments during the year.
We're also fortunate that ETS is our contractor for that and also has a contract with us for
science assessments in which they have promised to work with us to develop performance elements
of the science assessment.
So we have a lot on our plate to think about.
We're also very fortunate to have Mao Vang hitting our assessment division who is really
open-minded about all the possibilities that we may be exploring.
The reason we're starting with this kind of informal retreat, pretend it is, is because
this kind of work is not cut and dried, right?
This is we need to think together about our options, our students, our goals for an integrated
system of teaching, learning, and assessment, one that does provide useful information for
guiding practice and supporting students, that does measure higher order thinking skills
and performance skills, that is culturally and linguistically responsive, and today just
gives us an opportunity to begin to think and talk together without having to vote,
without having to come to decisions, but really learning.
We're going to hear from some experts around the country, and we're fortunate to have
one here in California.
Deb Sigman is going to both teach us some things and help moderate the session.
So I'm excited about the day, and Gabriella is going to also share with us as our assessment
liaison some of the ways that she thinks about this from her work in the classroom.
Okay, thanks Linda.
I'm equally excited to have this conversation.
As a classroom teacher, I always think, do we know what assessments look like at the
state level?
Do our members interact with assessments often?
And so today I want you to think of every student, regardless of their background and
what they look like or where they live, deserve access to an excellent education that empowers
them to achieve their dreams.
We must employ quality assessment practices that generate accurate, useful evidence of
student learning to support instruction and student success.
We want to rethink assessments as a means, not an end, a means to expand equity and close
opportunity gaps to inspire student, educator, and parent caregiver engagement, and to
promote a more holistic view of student learning.
Let's design assessments that inspire learning.
We want to access, assess what is meaningful to student well-being, learning, and
individuality.
Any assessment that we administer should offer a more continuous, equitable measure of
student achievement rather than a single snapshot that reduces student learning to a
single score.
As we embark on today's learning, I would like for us to see assessments as meaningful
and relevant opportunities for students to demonstrate what they've learned and enable
educators to tailor and adjust instructional supports to help our students thrive.
I want us to think about how we can best support our educators in the classroom to really
support that student that we have currently now in our class.
I know that all the teachers who are listening, who are thinking, these assessments are
really just a guide of how our students are doing, and continuously teachers are curating
assessments and planning, collaborating to help our students thrive in the class.
And this assessment is just a snapshot of where our students are and what supports we
can put in place to help them continue as they progress in every grade level.
All right.
Well, we are launching now, and I want to introduce my good friend and our colleague
Deb Sigman, who is currently the senior advisor at WestEd, but was at one time our state
assessment director.
So she's been thinking about these issues for a long time, and she will moderate our
first activity.
Thank you.
Thank you, President Darling-Hammond.
And it's so great to be here.
As your chair said, I've been in this business a long time.
Probably my current title is senior advisor, and I'd have to say emphasis on senior.
But I have been around for a long time, and my whole career has been pretty much dedicated
to assessment.
And so like your chair and co-chair, I feel very passionate about this and your assessment
liaison as well.
It's a really important aspect of our educational system.
I've always looked at assessment as an advocate for children who may or may not be able to
advocate for themselves.
And I firmly believe that.
So having quality assessments that do exactly what Linda was saying is so critically important
as we think about equitable education systems.
But today is your day, your day to think and talk, your day to really start noodling, if
you will, about what a great assessment system in California would look like.
You are the policymakers, so you have a lot of decisions to make.
So we're going to get started.
You'll note that you are at these tables, and these are your study groups, if you will.
And today's first talk is you'll see the questions posted on the easels up there.
So we want you to think about what do you appreciate about our current state assessment
system, our subject matter assessments, so our English language arts and our math, which
are the Smarter Balanced Assessment, as well as your developed CAS, your science assessment,
as well.
So think about what is it that you like about it?
What kind of information do you like about it?
What is it doing well, right?
And then your second question is in what ways do you see that the state assessments support
teaching and learning?
Because at the end of the day, that is what they are supposed to do, support teaching
and learning.
So what ways do you see them supporting teaching and learning?
So we're going to get started right away.
I want you to take a few moments, think about this, talk to your table partners, and you
have post-its at your table.
We want you to start writing these things, and then when you've thought about this and
you want to go post, we'd like you to go post to the easels.
You have two easels, they both have the same questions.
But take a few moments, five minutes maybe, Linda, for discussion a little bit, or discussion
at your table.
You could think about this as sort of appreciations on the one hand and aspirations on the other.
What would we like to see in an ideal world of a teaching, learning, and assessment system?
And it looks like both questions are on both tag boards.
So you can just go to whichever is closer to you and put your appreciations and your
aspirations.
Yes.
All right.
And you're allowed to talk to each other.
Yes.
I want to hear a lot of noise.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
And I'm going to go over to the boards and just try to synthesize what I see.
I'll start with the what do you appreciate about our current state assessment system.
Pretty similar on the two boards.
We'll talk about the use of technology with the with the assessments.
A big improvement over our paper pencil tests really create a lot of accessibility opportunities.
Folks like the interim assessments and that I think is over on the other board as well.
Opportunity for students to respond to constructed and selected response.
Really quickly.
Let's see.
Show us what they know much broader than for those of you who remember our CST system back
in the day.
So those are some things.
Let me move over here.
Common high expectations, so common for state policy and family.
So there's recognition that there's some transparency with our state assessment system.
Again, interim assessments appreciate the shorter format, appreciate the fact that California
sees assessments as only one measure when we're talking about the quality of schools
and so forth.
And let's see, again, interim.
So this issue of the system, right?
So the interim assessments being available and so forth seems to be a real highlight.
And then of course performance assessments provide various opportunities.
So that for the first time in our system, we brought in the performance assessment task,
which was pretty remarkable.
I had not had that before.
Okay.
So what are your aspirations?
What would you like to see our assessment do in order to support teaching and learning?
So I love this.
Integrate lesson design with formative assessments, sorry, and have these assessments build upon
the evolution of student, thank you very much.
Ensure there's interdisciplinary data, let's see, claim-level data, but keeping within
short time frame, right, short form time, right?
Develop teaching protocols to examine state assessments.
Interesting.
So a professional development, professional learning kind of aspect.
Voice recognition, I think that was over there as well.
Let's see.
All students have classrooms that are using interims.
Remember there's no legal requirement that we use them, they're an option.
And assessments can be more than a task, rather a process that gives students an opportunity
to demonstrate what they know.
The four C's, communication, collaboration, critical thinking, and creativity.
That's where you'd like to go, let's go over here.
Anchored in curriculum and available during the year, so kind of mimicking what they're
taught during the year, so it's not just a surprise at the end of the year.
Information beyond scores, right?
So we've added a little bit of that, but there's more we can probably do.
More open-ended inquiry that challenges students to use their minds more fully, okay.
Assessments that guide instruction and encourage and support high quality socially culturally
responsive teaching want to see tests that enable students to bring their own knowledge
and backgrounds, so being really culturally responsive.
Let's see, what did I miss?
Oh, projects and research that engage students and use multiple forms of representation.
So I think you have a clear idea of what you'd like to see.
I'd like to ask for any kind of, anybody want to add something?
Anybody have a question?
Anybody want to say something?
Yes.
Oh.
I forgot to put up one, which is figuring out the right assessment on the TK to three
side of the house.
So expanding the system for that TK to three, what would you hope that would do?
I would hope that it would be developmentally appropriate, that would both help both teachers
as well as families figure out how to work together on the early foundations, that would
incorporate many of the things described around the use of interim assessments so that it
time within the school year, and that it could be shared and aggravated at the state level
for the policymakers as well as families.
Great.
Anyone else?
Yes.
I was just thinking about the other end of the spectrum, which is at high school, and
how the summative assessments are only in 11th grade, and how while I wouldn't want
to necessarily advocate for more testing, I think helping teachers in the ninth, tenth,
and tenth grades better understand what's going to be on the test or understand how
to prepare students, just more integration at the high school level.
I think could be really useful, so it doesn't feel like it's just a one of out of the blue.
Teachers can use those interims at ninth and tenth, which many do.
They can.
Yes, you are correct.
Not required.
And then, member Escobedo, did I see your hand raised?
Embedded in the day.
Great point.
I was just thinking about what Sharon was saying.
I've been impressed in some of the states that are creating banks of performance tasks
that those become then rich opportunities for students in any grade level, not just
a tested grade, to experience inquiry learning and for teachers to then have rubrics and
evaluated that inform them about what the standards are trying to achieve and what students
are able to show.
My other thing I forgot to put up there was teachers involved in scoring open in their
tasks, because when you see the actual work that students do, you see their thinking.
You then know much more about how to teach them than if you know that they're a 92
or that they scored below basic.
That just doesn't give you enough knowledge.
So, figuring out how to actually see the work is important, too.
The chart behind me references opportunities for teachers to learn about assessments.
I think families need the same opportunities to really deeply understand the assessments,
the alignment of what that means for their child's learning, and what that means for
their future opportunities as they grow.
I would add, definitely in agreement with all that's been shared, one thing in the aspirational
column that I want to be sure that continues is the opportunity to be able to look at school
to school, district to district, for that comparability, finding out bright spots, finding
out LEAs that may need additional support to best meet the needs of their students.
So I wouldn't want to lose that as we go deeper into the richness that we know needs to happen
in our assessment system.
Keep what's working, right?
I just want to add a little bit to what Allison was saying about involving caregivers, parents.
Some of the workshops that we've had in the past have been involving them also in the
scoring and informing families about the rubrics that we utilize as teachers and having them
also go through the process because when they understand what we are looking for when we
score students, then they also know how they can best support their child at home.
Well put, yes, absolutely.
Any others?
Just briefly, I think also a reset on how we view assessments because oftentimes the
context in which we look at data can reaffirm historic inequities in people's perception
about different student groups.
So thinking about assessments also in ways that show students' assets and the wealth
that comes from different communities as opposed to consistently looking at certain
assessments from a certain mindset or disposition, if that makes sense.
Asset-based as opposed to looking at the deficits.
What strains students bring?
Yes, member Lewis.
I just want to comment on one of the post-its over there about UDL.
And I think incorporating just the principles of UDL to give students, to incorporate representation
of how they show what they know and how the work is presented to them and just incorporate
that in the preparation and also the follow-up to students' assessment and how they do on
the test.
So I think just somehow making that part of the protocol of our assessment is to look
at those principles of UDL.
Incredibly important.
All right.
Oh, absolutely.
Yes.
Not quite sure how to put this, but I'm thinking about in schools where perhaps, I was going
back to my comment about high schools and where in schools where maybe they're not using
the interim assessments.
I think working to ensure that when we're building our assessments, they feel really
of value to teachers so that, and they feel included in that so that they might be likely
to do things that are optional, whether that's use the interim assessments, get involved
in the way that you are, for example, Gabriella, but look to the banks of possible performance
tasks because I think teachers have a really high, like, they want what they do, they know
that their time is valuable in their classroom and they don't want to give it up, right,
for something that feels like it's solely about accountability and not really about
student learning.
And so really helping ensure that we're making that connection or we're prioritizing them.
Making the connection between assessment and teaching and learning.
Critically important.
Yeah.
Member McClellan, did you?
Oh, no.
Okay.
Anyone else?
Yes.
Member Rodriguez.
Yeah.
Great information.
I've really enjoyed everybody's contributions and I concur.
And also I wanted to add a little bit more to, I mentioned the teacher protocols.
So, like, I'm going through my national board maintenance of certification, right, and because,
you know, national board is performance-based, so I have protocols to reflect on my teaching,
which are very valuable.
And so I think about the experience that I've had with performance assessment, right,
whether it was at East Palo Alto High School, planning them for our students.
So it's just something that's embedded in my teaching, even though I didn't go through
edTPAs, for example, right, which I think, like, a lot of our new teachers that are coming in
through those assessment processes have that as part of their mindset.
So, you know, I imagine having protocols for teachers that we can analyze the data without
putting students in boxes, right, and saying, oh, these are low, low, you know, without
doing that, but just saying, okay, this is where they are, you know, and protocols that
are asset-based that we can see, like, this is what they know, how can we get them to
this level, and especially to make it look like it's not final, because I think a lot
of that mindset is still prevalent in our schools because of No Child Left Behind, this
finality to the assessment, but that it is an iterative process, that learning is iterative.
So, you know, I imagine that that would be, like, a wonderful way to have professional
learning that where, you know, we create performance assessments for students in our
subject area, right, you know, whether it's, like, world history or math, and another
thing, being able to see the gaps in thinking, like, maybe I didn't teach this the way I
wanted to because I've noticed a few of my students tend to, they miss this or the analysis
isn't as complete as I'd like it, right, how can I go back and fill in that gap, so.
That examination of student work is so great, as President Darlingham said, as well as kind
of giving the, making it really transparent about what those expectations are and so forth,
yeah.
And it was the analysis of my student work when I went through the national board process
the first time that was the most valuable learning for me as a teacher.
Well, that's wonderful.
Thank you all.
I think we're moving on.
Yes.
All right.
Thank you so much.
We have some experts coming on and I think maybe they're coming on this big screen.
I don't know.
I know the first person who's going to be with us technologically, zooming in, is Lillian
Pace.
Is she coming on here?
Okay.
So I'll just say that she is the Vice President of Policy and Advocacy for Knowledge Works,
and she was involved with the presentation, with the publication that you read as part
of your background reading, and there she is.
Lillian, can you see us?
I don't know what you're seeing on your end.
We can see you.
I don't know yet if we can hear you.
You want to say something?
Okay.
There we go.
I am here.
Just give me one second.
One of the fun things of presenting remotely is you're dealing with dueling monitors, and
I want to be able to see you guys, so I'm going to try one more thing while I present.
It helps to be able to see both the slide deck.
Okay.
Excellent.
Well, thank you so much for the honor to be here.
I really appreciate the invitation.
It was also really rewarding to get to listen to the aspirations that were covered in that
last exercise.
So a lot of what you shared will align with a lot of what I'm going to present here today.
As Dr. Darley Hammond mentioned, I'm the Vice President of Policy and Advocacy at Knowledge
Works.
We are a nonprofit organization that supports policymakers and practitioners to design more
student-centered systems and particularly focus on the redesign of assessment and accountability
systems to support those student-centered practices.
So I was asked to come here today to speak specifically to the national assessment trends.
So what are we seeing in this moment in time where there's a lot of education, a lot of
assessment innovation emerging around the country?
So I'm going to cover some of those trends and then provide a little snapshot into some
of the assessment tasks that we are seeing emerge in some of these states that are trying
to design more authentic assessments.
First, I want to start with anchoring in public opinion.
So there are a number of surveys that have been conducted recently that are really illustrating
that the public confidence right now in our school system is at an all-time low and that
particularly we're seeing more of a call to better prepare students to build decent lives
in their community.
This notion that parents and students want more real-world skill building in schools
and this belief from a majority, 74% of parents believe that the lack of personalization is
the problem with today's school system.
Lillian, are you trying to share your screen because we're not seeing your slides.
Oh, you're not?
Okay.
Let me try that again.
Let's see if you can try that again.
Thank you.
I happen to have seen your slides, so I know that that's your first slide.
You know.
You know.
That's right.
Okay.
Let's see.
Let's try this one more time.
Yes.
It's coming in.
It says, wait as content sharing is launching.
There it goes.
We got you.
You can put it on the slideshow, maybe.
All right.
Yep.
Okay.
Let's try that again.
Going back, so re-anchoring public opinion at an all-time low, a desire for better preparing
students to build decent lives in their community, this notion for more real-world skill building
in schools, and this belief that a lack of personalization, so as I said, 74% of parents,
that's a significant number, are saying that that is the problem.
If we drill a little deeper and start to look at the concerns about summative assessments
in particular, you can really start to see some issues emerging with our nation's education
system, and none of these will be a surprise to each of you, as I hear the aspirations
that you shared, but we're really hearing from stakeholders all over the country that,
you know, this over-reliance on multiple-choice items is not capturing that deeper level of
knowledge and skills that we know are essential to student success, and that means we're not
actually getting the full picture of student mastery or school quality.
Curriculum has become narrowed and often focused on this notion of test preparation, right,
and we hear a lot of that means instructional time is lost and students are not really benefiting
from the richness that you would hope to see in classroom settings.
Data is not actionable for instruction, and oftentimes that data isn't valued in the
classroom at all, and our students are experiencing testing stress, and they're also not
seeing themselves in assessments. They're not culturally or linguistically inclusive.
So I'm going to bring forward kind of two sources of information as I talk about the trends
that we're seeing emerge around the country to try to address some of those concerns that are
emerging around our assessment systems.
The first is the report that Dr. Darling-Hammond mentioned, which is called Measuring Forward.
This was a report that was put out from a group of organizations that are working together at the
federal level to help educate policymakers about the trends that are emerging in states around the
country as they are seeking to build more innovative assessment systems, and it was really an
attempt to try to capture as much of the information we could find in states as they're asking
critical questions and beginning to design new approaches to assessment.
And the second is recent interest from the federal level to increase funding for the competitive
grants for state assessments program.
So you can see in 2020 about just about 12 million was going out the door to support states
through competitive grants to support new innovative assessment approaches, and that funded by states.
2022, the next year of that competition, $29 million was going out to support 10 states or actually
11 awards, but one state was very lucky and got two of those awards.
So an infusion of federal funding is actually at play in helping fuel some of the interest in
assessment innovation.
So if you look at the map, you can see where this innovation is happening.
So the lighter blue states are the states that were featured in that measuring forward report.
The yellow states are states that received awards from that competitive grant program at the federal
level in 2022, and the green states are the states that not already had work underway, and it was
cited in that report and also received a grant from the federal government in that last competition.
So you can see the footprint is pretty significant.
There's a tremendous amount of activity happening around the country, again, responding to those
stakeholder concerns about problems with current assessments and a demand for a new approach in our
school systems.
So as we began to look at the trends across these states, we really saw them organizing around two
big buckets.
The first are these innovative design elements.
So what are the types of designs that states are looking at as they are exploring new approaches to
assessment?
And then the second category is how are states actually beginning to put supports in place to build
their system capacity for the creation of more innovative approaches to assessment?
So if we start with those assessment designs, there's really five areas that we saw emerging across
those states, and I'll note that it's important to remember that an assessment approach often
incorporates several or many of these design elements.
They are definitely not mutually exclusive.
In fact, they're great when they incorporate many of these elements, if not all.
So know that while I'll talk about them in isolation, the designs we're seeing emerge are really
tackling many of these elements.
So instructionally embedded assessments.
So these are assessments that are not divorced from the curriculum.
They're not happening in a separate experience that have no connection to the curriculum that has been
administered throughout the year.
So students are sort of aware of kind of the content, the topics they've experienced, and it's building
on what they're doing in the classroom.
Performance assessments enable students to really demonstrate mastery of a conceptual understanding in
a new or novel context.
So this might be things like, you know, a complex writing prompt.
It might include something like a science experiment.
So I love to include this nontraditional graduation requirements because we often hear from states
it's really hard to innovate right now because of the constraining environment at the federal level.
And while I would concur that there are significant constraints at the federal level, it's really
interesting to see states beginning to move into the graduation requirement space as an area
that's completely within their authority to begin to build capacity within their state for more
authentic assessment experiences.
And so this is where we're seeing states, you know, either provide opportunities for students to,
instead of maybe completing a traditional course sequence, to engage in a rich performance capstone
experience or a portfolio defense as a means of earning a diploma and demonstrating mastery of the
knowledge and skills and dispositions that the state has outlined are critical for success.
So I'm stuck.
There we go.
Shared quality criteria.
So these are the tools and templates and processes that need to be created alongside these new
assessment tasks that help educators have common language.
So what does success look like on an assessment?
How am I supposed to interpret and have common expectations as I'm scoring these assessments at their
classroom base?
What kind of standardization needs to happen across that experience to ensure that we are experiencing
quality implementation from one district to the next?
And the last, and we heard some reference to this right at the end of the exercise you were just doing,
so task and item banks.
So there's a lot of interest around the country in this particular area.
So the idea that either a state or a vendor or teachers are creating a set of performance tasks,
rich assessment items that are validated in some way by some sort of third party to ensure that they
are of a high quality and aligned to the expectations of learning in the state.
And then they live in a bank that then educators can pull from at any time and use in their classroom
experience.
And I think this has become an attractive option because it is helpful for managing quality but also
provides flexibility to educators to use as needed to support their instruction.
So the second bucket was system capacity.
There has been an explosion of advisory committees across the country.
States are beginning to bring their diverse stakeholders together to ask these critical questions.
What vision do we want for assessments?
What innovative assessment designs might we want to consider?
I'm trying to make it a more engaging process than previous assessment design processes have been in
states in the past.
At the same time, we're seeing a lot of interest in assessment literacy, professional development.
So if we're going to bring more authentic assessment practices into states, we need to make sure that
educators have the supports necessary to be successful and to be able to implement the data from those
assessments in their classroom in meaningful ways.
And some states have taken that a step farther to say we actually want to build an entire professional
learning community, a network of educators and leaders that convene regularly to test best practices,
to calibrate scoring of assessment tasks, to really deepen their knowledge across the state and build
quality.
And the last off-lag is the multistate network.
So that learning community, not just happening within states, but we are beginning to see states working
together to tackle these challenges because the challenges are common in many ways.
They're facing the same concerns from stakeholders.
And there's a lot of interest in creating some efficiencies and learning and exploring those assessment
solutions together.
So I'm going to feature a couple states, some examples of performance tasks that we're seeing emerge, just to
give you a little bit of a flavor of what these types of tasks look like.
I wanted to start with Massachusetts.
So they are in the process of building out an innovative science pilot assessment.
This was actually an assessment that has been approved to pilot through the Federal Innovative Assessment
Demonstration Authority.
Massachusetts is a state that's always been at the top in the nation for performance on their state MCAS
assessments.
But what the state is beginning to notice is that they are creating ineffective teaching practices that have
spread across the state because teachers are teaching to ensure success on that assessment, but we're losing
a lot of the deeper learning experiences that they know are so critical to their post-secondary and workforce
partners.
And so they wanted to push their own thinking about what assessment could look like in the state and begin to
bring in these richer assessment tasks.
So they're looking at fifth and eighth grade.
They may expand to high school in future years based on how the pilot goes.
But they're being intentional about creating a system.
I think this is an important thing to really focus in on.
So while they're looking at adding these summative or these performance tasks in their summative assessments,
they're being intentional about aligning these classroom embedded performance tasks as well so that students are
experiencing these concepts of learning in a classroom-based environment.
And when they get to the summative tasks, they're familiar with how to navigate some of these rich simulations with new
content, of course, as they're evaluated on those assessments.
So you can see there are some of the goals very similar and meant to address some of the concerns that I shared earlier,
trying to get a more deeper learning.
They want improvements in classroom instruction.
They want to make sure that this is engaging and culturally inclusive and relevant for students.
A couple enabling conditions.
So as I mentioned, they did receive federal approval for the Innovative Assessment Demonstration Authority.
At the same time, they received almost a $3 million reward from the U.S.
Department of Education in 2020, and they've received additional philanthropic investment to support that work.
So this is a snapshot, and I really want to emphasize snapshot, because these performance tasks are rich.
They are pages of depth and instruction.
And so what you were looking at is component three of an eight-step task.
But the reason I wanted to take this image is because it shows you a simulation.
And again, remember, this is a summative assessment.
So what the student here is being asked to do is they're going to manipulate this simulation to look at these barriers in the bottom left corner.
So there's a U barrier, a J barrier, and an I barrier.
And they're going to try different barriers out in the simulation while adjusting the amount of rainfall to try to determine which
barrier is most effective for reducing the amount of sediment that's going to flow here into this lake.
And so what they're being asked to do is to run five different barrier designs.
And those will populate up in the A, B, C, D, and E categories there at the top of the simulation.
And at the end, they're going to use that information to make determinations about which barrier they think is most effective.
And you can see while they do have to use drop-down approaches here, again, there's some limitations around the summative requirements and the technical
quality implications that are set out through the federal peer review requirements.
They are able to require these students to put their saved model in here to show that they completed the performance task and that their saved model was the best example.
So there may be different responses that students would share here and still receive a correct score.
So the state, as I mentioned, has aligned performance tasks that are classroom-based.
And so this is an example.
There's a lot of words here, and I'll sort of talk you through what's going on here.
So an educator would be using this type of a task in the classroom experience to ensure that the student is getting experience with things like designing of simulations.
So this particular performance task is getting at Newton's third law.
We're looking at collisions in soccer.
So they're given sort of three different scenarios in which collisions happen.
So you have a header collision where you head a ball, you have two players that collide, and then you have a player that would hit their head on the ground.
And there's some different attributes to what might happen in those collisions.
And they're going to draw and explain how the amount of force on the head would compare to the force on the object across these different scenarios.
They would be working in individual work as they're thinking about that.
Then they might switch to group work.
And I really truncated this down, but some examples of some of the group work prompts.
So they would actually design a simulation to look at the difference between mass and speed.
And so they might use a cart and a block, and they would have a similar simulation like you saw in the previous slide.
And they would create a data table in their science notebook.
They might be asked to manipulate the speed in certain ones.
They might be asked to manipulate the mass and they record that data as a group and make observations.
And then they might also be given things like Play-Doh or a paper towel or a sheet of foam.
And they might be asked to design an investigation and again to receive a series of prompts to come to some conclusions about which different materials affect the force of a collision.
The second state I wanted to share was Hawaii.
Hawaii is also trying to balance a system of assessments where they have these smarter, balanced, shortened, summative, computer-adaptive assessments
complemented by these teacher-developed, classroom-based assessments through what they're calling the Performance Assessment Development Initiative.
They are trying to tackle all of the federally required tested grades, the 3 through 8, once in high school, in ELA, in math.
They're really trying to be intentional in this pilot right now around calibrating those performance expectations between the PATI assessments and smarter balance so that there's coherence in their system.
They want to make sure that educators have access to training as they're accessing the task space.
They want aligned curriculum guidance for every single task.
They're looking at building assessment literacy, and they're also asking this question about whether they should develop and adopt a skills profile on each of the individual student reports.
So in addition to kind of that knowledge acquisition, looking at how skills are emerging for students as well.
They also have received two federal grants that have supported this work, and they continue to say they're looking towards applying for the Innovative Assessment Demonstration Authority,
but currently are working on building the capacity around these classroom-based assessments.
And just a quick example from Hawaii, this is a grade 6 ELA task.
So this is about tourism in Hawaii, really trying to bring the community experience that students would be familiar with from their everyday life.
And they're focused on argumentative writing.
So in this particular example, the state government of Hawaii needs to make a decision about tourism,
and students would receive examples of evidence from across a range of texts, might look at tax receipts, might look at effects on the environment,
and they're going to read through all of those sources, and they are going to form their own argumentative position on what the state government should do.
So the last one I wanted to mention is the multi-state collaborative.
So again, as I mentioned, states are starting to band together to try to solve some of these issues.
So the SPA-LC, which is the State Performance Assessment Learning Community,
is now over 25 states that are working together to develop these more authentic statewide assessment systems that are centering high quality teaching and learning.
And what I actually wanted to share, so again, they're working on best practice.
They've recently developed a set of design principles.
So we need to think about quality when we're building these systems.
So what do they say are the critical design principles for the development of these systems?
So they came up with six, and the first was that these assessments need to be authentic.
So if, you know, if we know a particular discipline requires master of certain knowledge and skills,
how are the assessments centering those concepts in the assessment experience?
They need to be anchored in the curriculum, right?
So not divorced from the curriculum, but really embedded and informed by the curriculum experience.
They need to be educative, which means that educators and students are building their understanding of teaching and learning.
So one of the common criticisms about multiple choice tests is that they reinforce ineffective teaching.
It's exactly the problem that Massachusetts is trying to solve.
So how do we ensure that the assessments that we're designing are reinforcing that really good,
high quality teaching and learning that we want to see in the classroom experience?
We want to ensure assessments are developmental and asset-granted.
So what do students know?
We don't want to just tell students you're failing in science, you're bad in science.
What does a student know?
What can they do while also surfacing the progress relative to that student's own performance?
I already mentioned principles of universal design for learning, cultural responsiveness.
Those are critical.
We want to make sure that assessments are reflective of and responsive to learners.
And lastly, that assessments are being used to influence instruction.
So that data is coming at appropriate times and at a source of information that's meaningful for educators that they can use to improve their instruction.
And the last thought I'll leave you with before I close is really centering in this moment.
So why is now a good time for states to design more authentic assessments?
Why are we seeing this explosion of interest?
So as I mentioned at the beginning of my presentation, so stakeholder demand is at an all-time high.
I have yet to find a state that I have entered that loves their current assessments.
Stakeholders want something different.
At the same time, federal leaders are looking for state proof points.
I was just on the phone this morning with the Senate Health Committee, and they are saying we want to know what states are doing.
We need help understanding what's possible.
Federal and philanthropic investments are growing.
Improvements in technology are really changing what's possible when we think about the design of assessments.
There are other states to learn from and with.
You don't have to do this alone.
There are so many state networks that are emerging that are asking common questions, and it's encouraging and comforting to know that there are others.
And lastly, there's many pathways to innovation.
So sure, you could tackle that summative assessment, but you could also focus on rich formative assessments.
You could look at graduation requirements.
You could even focus on building out these shared learning frameworks.
So how do we evolve from our standards, which are critical, but also begin to think about these knowledge and skills and dispositions that we know are essential to student success.
So lots of opportunity out there to innovate.
It's a really exciting time.
And there's rich examples that are emerging all over the country to learn from.
And with that, I will go ahead and close out and pass to a colleague.
Thank you so much.
We're going to move pretty quickly to our next speaker, but I do want to see if there are any clarifying questions that people have.
And then we'll come back around for deeper questions after we've gone through the panel.
Any clarifying questions?
Some applause over here.
Let me just ask one.
When you were describing, for example, the rich tasks in Massachusetts, are those being designed in such a way, going back to the question that Cynthia asked, that they'll be able to produce comparable,
aggregable scores at the end of the process?
Yes, absolutely.
So because this particular assessment is being designed through the Federal Innovative Assessment Demonstration Authority,
that assessment will go through the ringer of federal peer review to make sure that it is meeting all of those designations.
And so the state has really been working to try to figure out how to ensure that they can meet standards around comparability.
They have a team of technical experts that have been helping them do just that.
And so it's our understanding that they have not only hit that standard, but they are receiving some early results that they're still going to be vetting,
but that show that students in these innovative environments, that they're actually seeing gap closure from the students who are at the very sort of lowest levels on the proficiency scale.
They're seeing those students come up, whereas the comparable results for students on the MCAS, there's no movement.
So because they were able to achieve a standard of comparability, they're able to begin to make those kind of determinations about the effectiveness of this innovative science approach.
Thank you.
And speaking of science, our next speaker is going to come on and Steve Pruitt should be appearing momentarily.
And Steve is sort of the godfather of the next generation science standards.
He oversaw the process of developing the standards and then went off to be commissioner in Kentucky and is now the president of the Southern Regional Education Board
and can tell us everything there is to know about science standards and assessments.
Steve is coming on. There we go. Thank you. Great to see you.
Thank you. That's such a nice intro. I appreciate that.
It is great to be back with the California State Board of Ed. It's been quite a while since I've been with you and I wish I could be in Sacramento.
I always enjoyed that trip.
As Linda said, I've been with this whole NGSS thing since the beginning, since the actual framework was even being developed.
So I know we're running a little short on time, so I'm going to run through my presentation fairly quickly.
But what I hope to show you are that when these were developed, when the framework for K-12 science education was developed by the National Research Council
and subsequently the next generation science standards were developed by the 26th lead state,
it was with the reality of where we were headed in the workforce and where we were headed in terms of our economics and workforce environment.
We have entered this fourth industrial revolution and therefore the idea that we can simply stay with recall and that sort of thing on assessment,
which ultimately drives how we do a lot of instruction, we knew we had to really move away from that.
You could go in right now and into an AI program that's easily accessible on your phone and you could write an entire report just based on a few questions.
So it really drives home the point that computers are no longer learning from us, they're learning with us.
The thinking that goes into this is a whole other level than what we have traditionally seen.
So when the NGSS were developed, it was developed with the idea, I used to say, to perturb the system.
If you ask some psychometricians, or as I call them, psychomagicians, because they do magical things with numbers,
they would say we might have even broken the system because for the first time we were really focused on a three-dimensional perspective
and most importantly, a three-dimensional performance.
These standards were developed with the specific intent that students do science rather than view science,
that it was really something that helped, that focused on making sense of the things around them.
So I'm not going to go through this in depth, but I'm going to start here quickly.
As Linda mentioned, I am a former state superintendent of Kentucky Education System
and have gone through a similar process once you guys are going through.
You really do have to take some time and know where you want to go.
This is not just, oh, we want to go build some tests.
Lillian did a really nice job of laying that out. There's some real conversations that have to be had.
The thing I'm going to point out on this slide just very quickly is the reporting versus messaging at the end.
I believe reporting is actually still an untapped conversation.
I think that states could do some really great things if they really think about how they want to report the assessment results
and how that messages to the field what's expected of our classroom teachers.
But that is a pretty in-depth conversation, and so I would just say to start with that.
Very quickly, all of you, I'm sure, have been around or you've heard people talk about the science.
Basically, there are three dimensions.
Scientific engineering practices, which is how scientists accumulate and communicate knowledge.
Cross-cutting concepts, or how we look at phenomena and how things are connected across the different branches of science.
And of course, disciplinary core ideas is the stuff. It's the content that we all know and some of us love.
When the standards were being developed, if you've ever looked at them, you've seen that there are not the traditional verbs that are in standards.
We intentionally went away from the web's depth of knowledge or the Piaget verb,
because what wanted to drive were the science and engineering practice.
In other words, again, a way to message students should be performing these, not simply learning those.
It was a very long and deliberate conversation that these were not going to be called just standards.
These are student performance expectations.
And so doing this is actually kind of an interesting thing because when we talk about cognitive complexity, it changes.
I'm not going to go through this slide very in-depth, except I'll point out, notice the blue.
Use models to organize, use models to predict, use models to communicate.
These practices are at such a cognitive level, they actually just doing on a multiple-choice test, you would not actually meet the spirit of those standards.
Cross-cutting concepts are the same way.
It allows us to look at different aspects of phenomena, whether it be patterns, causality, or even systems.
This is actually a nice representation that comes out of San Diego County.
So blending these different core ideas, we have life sciences, engineering, earth, space, and physical sciences.
And the whole idea is at the end of the day, students make sense of phenomena by blending these three things to use as evidence to explain the phenomena or the problem they're trying to solve.
I'm going to quickly run through this because I know we're running short on time.
I wanted to give you a quick look at how instruction is being approached in many ways.
At SREB, we actually developed a set of instructional practices of how teachers could be constructing their instruction in such a way that it actually would get to the three-dimensional aspect.
So they are basically a practice to making sense of phenomena, developing questions to plan and carry out investigations or design solutions,
gathering data, reasoning how evidence supports the explanation for the causes of the phenomena, engaging in academic discourse, presenting evidence of learning,
communicating reasoning through individual performance, and applying science learning beyond the classroom.
Here's what I want to point out to you.
This was developed with the intent of the framework in the NGSS.
So look at how many of those things are performance-based.
So when thinking about a new test, a new assessment for your state, the very intent of that is really about pulling students' knowledge out of them and let them really show how they can interpret what they are seeing and what kind of evidence they're able to collect.
Throughout the entire realm of instruction, the whole design was that you should constantly be assessing, whether it be formative assessment, midpoint, summative, all of those things are going to be evident.
For the sake of time, I'm not going to really go through this.
You all have this, but what I did was I laid out for you how a teacher may consider going through and developing instruction.
These three performance expectations actually would be used together in this unit of instruction, and so the assessment would actually be reflective of all three of those performance expectations.
But what I'd like to do is sort of move us into talking about process a little bit.
This is actually the flow of instruction.
So again, investigation, phenomena, develop a model.
It's really hard to develop a model onto simply a multiple-choice test.
All of these standards were really, from the very get-go, developed so that students could perform what they know.
It's a way to overcome a lot of different barriers.
It's a way to overcome a lot of different bias that traditional standardized assessment creates, especially with some of our students who are struggling with English learning or are actually our traditionally underserved population.
Like I said, I'm going to just skim through this because I want to get to this last part.
When we talk about assessing 3D standards, the things that we've seen, I'm not going to repeat these because Lillian did such a great job of pointing these out.
But these are things that part came from the Board on Testing and Assessment, which is another arm of the National Academies of Science, when they did a study on how should we be assessing the next generation science standards.
And what they came out with was the idea of a true system of assessment, meaning that the one-stop snapshot is simply not enough to be able to fully see if students are able to fully make their thinking visible and to make sense out of the different aspects that they have.
I'm going to point out Nebraska as an example here.
I actually had the opportunity to work with Nebraska in the early stages of their developing their task library.
This was a really great idea, and I think what it does is it allows teachers to be so much more involved in the assessment process.
So many things we do with assessment, we have to tell teachers, hey, don't read the test.
There's a security issue.
Hey, we're going to just send you the report.
Doing things with curriculum embedded instruction and with task libraries actually gives an open window that allows teachers to feel like they really are part of the assessment system.
Having teachers feel left out is a major problem.
And this was a great way to be able to do this.
So Nebraska, they developed a secure set of tasks.
In this, the teachers can use these tasks as part of a school or district-wide assessment initiative.
Some districts used them with their own systems and some did more creative things with them with creating, for instance, learning modules as well as task templates.
So there's an example here where they're looking at the human adaptation on the Tabishan Plateau.
And students are using these or teachers are using these rather during instruction to do checkpoints.
And again, one of the things that kind of I think has created a lot of issues in the current set of standardized assessments is the distrust that teachers have of what's really on the test, who really makes that decision, and does it really reflect what my students know?
And having these task libraries are pretty incredible.
I'm going to talk about that a little bit more in just a second and you'll see why.
I also just wanted to point this out.
AP Computer Science has done a really interesting thing with their AP Computer Science principles task work, where they actually, they're basically between six and eight performances that students need to do in this course.
And it leads toward their overall summative assessment of their AP score.
In Kentucky, what we did was we took this, we formed a partnership with Code.org and with College Board, and we actually use this as a science course.
Now, I personally have issues when we just make computer science blanketly a science course.
But in this case, we felt good about it because the six to eight projects were all based in science content.
A science teacher was trained in how to do the instruction here.
And at the end, these performance tasks not only gave us a great view of how they were able to manage computer science principles, it also gave us a great view of how much they were able to make their thinking visible because of the projects they were able to prove that,
hey, I really understand plate tectonics.
I really understand how erosion works.
I really understand weather systems because they were developing these computer-based simulations and modules that actually showed the science, but also to meet the function of the actual AP course.
Those were aggregated and were able to be used to determine whether the student was successful and had earned college credit in the AP course itself.
So here's what I'd like to very briefly leave you with.
As Linda mentioned, I'm the former commissioner of education in Kentucky.
You can imagine being the godfather, as Linda said, of NGSS, no state I ever was going to be in charge of was ever not going to do science.
And we certainly were not going to not do science the way it was intended.
So when I got to Kentucky, there had already been a lot of work done.
And we were committed in Kentucky to making teachers an integral partner in developing our assessments, but we were also committed to having a full system of assessment.
So we basically had a couple of goals that we wanted each component of the system, which included classroom embedded assessment, through course tasks, and state summative assessment.
We wanted to really make sure that each of those purposes were clear, were clear.
And in particular, we wanted the through course task to be a process for calibrating three dimensional instruction and student outcomes.
So the three things work together.
In short, here's what happened.
Classroom embedded assessment were developed by teachers in their building.
We provided a lot of a lot of professional development.
Through course tasks were created by we brought together roughly 100 teachers and taught them over a couple of years how to write these tasks.
We vetted them. We did all the things that needed to be done.
And then I used to kind of jokingly refer to it as the assessment closet where Nebraska College Library.
My thing was teachers should be able to go to an assessment closet, pull out their task at the right time of the year and be able to provide that to their students to give checkpoints.
And then, of course, the state summative assessment.
I'm going to talk about the through course task here in more detail in just a moment.
So we wanted to reflect on the process and structures that are in place or that need to be and identify ways to support implementation of the three components of the assessment system.
These were the three things that we wanted to be number one in our priority.
We set those before we ever set anything else in motion.
So the way all of this works is all of these things should provide evidence that students are learning the standard.
KAS stands for Kentucky Academic Standards.
They were also an NGSS state are also an NGSS state.
So all of these things should be working together.
So it was a full on system.
The through course test process, which is what I wanted to spend the majority of my time on.
And I know I'm running late here.
Was actually developed to be a process that allowed for us to provide a lot of training on how to plan for the task facilitation, how to actually facilitate tasks and how to post the task analysis.
We did a very thorough job of doing PD throughout the state.
We used 100 teachers who were writing these also as the champions and also the trainers so that there was this whole proliferation of hey, there's nothing to hide here.
You guys get to be a part of this system.
We also designed it where a third of that group rolled off every year.
So we always were bringing new blood to the table for the development and for the review of student work.
In this, what we did was we felt like and we know how it was in Kentucky.
It's a very local control state.
We could not be seen as controlling the curriculum from Frankfurt.
So we made a focus on saying here are through course tasks.
They were at every grade level.
Every school had to do three a year.
But here's the deal.
We did not make that part of accountability, at least at first.
And we said the one thing you've got to do is you've got to collect student work and follow our student work protocol and deliver one piece of student work, just one, to the to the Department of Education every year.
And then we convened about 200 teachers to go through the student work protocol at the state level.
And we reviewed the state, the student work review of the teachers at the school level.
And what that did was it allowed us to really evaluate that student work relative to the to the success criteria.
It helped us refine practices based on shared experience with teachers really got to collaborate and understand.
Oh, I didn't realize that's what students should be doing.
It helped them under expand their understanding of what their own instructional decisions were all about.
But for us at the department, what it did was it gave us representative sampling of what was going on throughout the state.
It helped us see if students were really utilizing sense making.
It was not used to evaluate district schools or teachers.
It helped us define student capacities.
But here's the big deal.
It also informed the Department of Education on what our future professional learning should look like.
If we could see where, oh, our teachers are still struggling with student work analysis, we design that.
If we saw we're still not really getting the whole 3D or they're not getting this particular practice or they're not getting this particular content,
we were able to stay level to redesign PD very specifically to be able to support those students.
So with that, I will cede my time, but I'm going to stop with just one final thought here.
And I know I really ran through that quickly.
This is a great opportunity, and Lillian's absolutely right.
The time is right.
When I was the commissioner in Kentucky, I had a lot of opportunities, some I sort of took.
I frankly had a rather public disagreement with the department at that time.
And it was actually about the same time California was having a pretty significant disagreement with the department.
And basically, we said, we're going to get this right.
And I told the testing vendor, I said, I signed your check.
And if you don't do exactly what our folks say need to be done, I'm not going to sign your check.
And it's amazing how quickly they get on board when that happens.
And so it was a very deliberate.
It took time.
It took effort.
It took realizing that teachers had to be a partner in what we were doing.
And then the last thing I'll say is I go back to I laid out the goals for what we wanted to do from the very beginning.
As the State Board of Education and as the Department of Education, setting out those clear goals keep you on track.
And this is not going to be something you can flip a switch.
It's going to take time, going to take investment, but it's worth it because the way our students are going to be involved in the workforce going forward,
the way they can be successful and be part of the economy is they are going to have to be involved in performance assessment.
And I say that because every day of their life is going to be that we're predicting in the South that by 2030, we may see as many as 18 million unemployable adults,
not unemployed, unemployable, because they simply don't have the skills to be involved in a workforce that is going to be demanding of performance
and of critical thinking and of taking their task and making sense of it to be a part of that.
I mean, we already know you can't go to a McDonald's and just order.
You have to order it on a giant iPad.
My wife and I had dinner a couple of months ago at a restaurant.
We never saw a person, but a robot delivered the meal to our table.
Those are the jobs of the future.
The people behind the scenes that are running the robot.
So I believe performance expectations and performance assessment are really the only way we're going to be able to move this ball down the field.
So thank you so much. I appreciate you letting me be here.
Hopefully my accent wasn't too bad and you were able to understand most of what I said.
Thank you so much, Steve.
Let's take just a minute to see if there are any clarifying questions for Steve before we go to our last speaker.
And I hope we'll have everybody pop back up on the screen so we can get into more discussion as well.
Any clarifying questions for Steve?
Well, I have one, but I'm going to let you go first, Kim.
Thank you. I just wanted to return to one of the examples that you gave of the AP computer science course and how that was evaluated, which is really fascinating.
And how what I guess what you can share about how that assessment is done collaboratively for work in groups.
I think there was a portion of that that was individually individual submissions and video submissions, but the code needed to be developed together.
And as we were just talking about sort of future skills of the future student body and workforce around having both critical thinking skills, collaboration skills, communication skills and how how they functionally did that practically.
So, you know, it was a pretty fascinating thing to watch.
It was not handled the way we have traditionally done group work in classrooms where we say, OK, we got this group of four.
Here's your task. Turn it in in an hour or in a week.
And it was a lot more deliberate where there were very specific assignments given to each of the students where they actually were held accountable, I guess you could say, for their particular part in the group.
And, you know, nobody could be a reporter.
Nobody could be. I mean, there were actual aspects of how this was coded.
So, you know, an example, for instance, that I remember is one of one group was working on erosion control because we tended to use a lot of earth science in our AP computer science.
And there were different aspects of developing the computer model that different students were responsible for.
So, you know, one student might have been responsible for really understanding and developing the code to show how, you know, water versus ice affects how soil is moved.
Another student was really involved in the consistency and makeup of soil in different parts of Kentucky.
So, you know, whether this was something that was happening in Eastern Kentucky and coal mine country versus, you know, in the runoff in Louisville.
So there were very specific tasks assigned to these kids that may have resulted in a total cumulative collaboration, but they were things that could be very clearly attributed to a student as part of the overall goal.
And I would just say kudos to pointing that out with regard to the collaborations.
We know that that's what industry is asking for is the ability for students to be able to collaborate and work in teams.
It's whether you call it 21st century skills or we call them workforce skills that are necessary.
So I actually I think doing this doing the way the college board did, but also the way we are talking about performance assessment actually brings those durable skills.
We also tend to call that durable skills because they should last over a lifetime.
It's how those durable skills really can be seen versus just talked about.
Get there. You got to develop them. That's right. Question. And then I see that something has a question.
Thank you, Stephen. On slide 10, you talked about the 3D performance where we talk about practices, core ideas and cross cutting concepts.
Traditionally, when we think about science assessments, we would test the life science separately from Earth and space science separately from physical science.
Does this new way of thinking, does that shift when we're thinking about what an assessment would look like?
Because in California, we called the preferred model in middle school the integrating all of these aspects together.
So our many districts are implementing the integrated model where they're also that affects teaching, learning and the curricula that's being used as well and the sequencing of that.
Just if you can elaborate a little bit on that, I'd appreciate it.
So I'll tell you that when the framework was being developed and when the NGSS was being developed, I think one of the wishes was that it would make a shift.
We are still kind of living under the committee of 10 from 1873 who made the decision that in the U.S. we're going to teach these things separately.
And the reality is what you kind of do is you you really set up a black box of learning.
So, you know, the biology teacher is going to teach about ATP and about energy in the cell.
But the problem is to understand that you actually have to understand the chemistry of how phosphorus actually attaches to the ATP.
And if you really want to understand that, you've got to understand the energy that happens in physics.
And so it really is a whole other type of deal where if we really wanted to move this forward, having even if it's a modified integrated where people are starting to wreck.
And that was one of the reasons that cross cutting concepts was so important because those span all those areas.
But it's also the reality of, you know, we have to figure out that for our students to see science and to really make sense of it, it means we have to to expand their exposure to more of the sciences.
The other aspect of that, which you are actually pointing out may not realize is those practices in cross cutting concepts.
They actually become more alive when they are being looked at across different disciplines.
But when we hold up one simple discipline, when biology is our only high school assessment, well, biology in and of itself doesn't make you scientifically literate.
Now, given I'm a chemist, so maybe I'm a little biased, but, you know, I think it's really important that you actually understand that larger diversity of science.
Because what it does is it makes you a better thinker because you see those different practices in different contexts.
Thank you.
Well, first, let me say thank you so much for the presentation.
Extremely engaging and thank you so much for taking the time.
I want to ask a question in relation to its slide thirty three, and it's the through course test process.
I noticed as you were going over this in it on the slide, it does mention that this is something that would take place and impact teaching and learning at every grade level.
So my so my question is how does the planning for the task facilitation look differently or does it look differently when planning for lower grades or younger children?
Let's say first and second grade, kindergarten, first, second or older students.
How how might that planning for task facilitation look the same and look different depending on the grade level?
So it looks different. I mean, you know, there's the obvious right of, you know, a third grader learning about diversity of life is going to look very different than a tenth grader.
So there's that. But the way we tried to approach it was especially in case the areas that we were able to well, and even six, eight, but really focusing in K5 how to connect the other content areas because most of our teachers were self-contained.
So, you know, rather than having them feel like they're having to stop dropping tests, you know, let's let's think about how we can utilize the skills of reading the skills of math and bring those into a little bit more for representation in the task.
We gave our teachers a lot of latitude in this because this was and this was early.
I mean, this was back in 2015 when we started this this kind of journey.
And what it really did for us then is it kind of in some ways it confined us because we our teachers were scared because we were actually saying you've got to do three of these tasks at every grade.
And of course, you know, as you can imagine, we had some elementary schools that were like, I'm not sure if we even do science in elementary, which, you know, freaked them out because my role was when I came to visit your school, you had to take me to a non-tested science class.
But we did have to be a little bit more deliberate in K-5 about showing how those other aspects of the students learning fit.
Now, we made sure to have the meta tags in middle school and high school to reading math and where possible other parts of our curriculum or other parts of our standards.
But I would say in K-5 a pretty big push was recognizing the self-containment of an elementary classroom and how to not look at it as a barrier, but actually how to look at it as an opportunity.
Linda, I can see you're saying something, but I can't hear you.
I think I turned my microphone off instead of on. I just said thank you so much. And we hope you have the time to maybe hang on a little longer.
But if you have to run, it's OK.
Unfortunately, I am so sorry I have to, but I am on my legislative visit and I have a group of legislators waiting for me for dinner.
And so, you know, you know, you don't tell them no.
I actually have to get to dinner, but thank you so much for letting me be a part. And I'm always happy to help California anytime I can.
All right. Take care.
Thank you.
And now we have the wonderful Deb Sigmund to help us think about teacher scoring.
Yes. Thank you, Linda.
Waiting for my PowerPoint.
There we go. OK.
Boy, those were just great.
And I, too, am going to try to move this along because we are trying to get back on schedule.
I want to talk about, and it's something that both Lillian and Stephen kind of talked about, and that's this professional learning aspect.
It is so important if we're going to have these new and innovative assessments and assessments that we really want to impact teaching and learning.
It is really incumbent upon us to make sure that our teachers are part of that process, right?
And that they have opportunities and time to develop their own skills.
So I'm going to focus on a project that I had the good fortune to be a part of.
And that's the affectionately known as the Beale Project, the Building Educator Assessment Literacy Project.
Just a reminder, and maybe you don't need reminding, but this is our California Education Code.
This went into effect in January of 2014.
It actually was still here.
We worked really hard to make sure that this got into the law.
And that was that its primary purpose for these assessments were to assist teachers, administrators, pupils, and their parents
in improving teaching and learning and promoting high quality teaching and learning using a variety of assessment approaches and item types.
It was really important to get that in because we were totally changing the way we thought about assessment.
So that's there.
We have full support of the law behind our development of these new and innovative kinds of items.
You know, I think about why do we assess, right?
And certainly the speakers talked about different reasons.
But from a state perspective, you know, and from a school perspective, thinking about a way forward, right?
It doesn't tell you what to do, but it may point you in a particular direction.
Hopefully making informed decisions, right, if we use that data appropriately and correctly.
Triangulating the information.
California uses lots of different data sources to make decisions, classroom decisions, school-based decisions, thinking about accountability decisions.
Making those informed instructional decisions.
And then finally, policy and programmatic decisions, which sit squarely into your responsibility.
And each of those really is a different audience, right?
So those different audiences think about assessment differently.
So this building educator assessment literacy was really about engaging teachers, educators, through professional development,
focused on the understanding of and using performance tasks.
It was, it started back in, let me give you the, let me talk about what smarter balance performance tasks are first.
So this, I just want to remind folks, this is kind of the context within which we were developing this professional learning.
And that was really devoted around the smarter balance, right?
We were moving from a totally multiple choice, selected response kind of test.
And we knew we were going to have to train our teachers, give them information, include them in the process,
so that they could effectively bring our kids along with us.
So in the smarter balance context, what are performance tasks?
Well, they're collections of questions or activities, and they lead to a culminating performance, right?
They're not quite as long as the one that Lillian talked about.
I think the eight step process are meant to measure those capacities, such a depth of understanding,
you know, really hitting those critical thinking skills.
That's what we were focused on.
We wanted people to think more deeply about what we were asking of our students and what they could demonstrate.
So measure a student's ability to demonstrate critical thinking and problem solving.
And then challenging students to apply their knowledge and skills to go to look at those real world complex problems,
which is exactly what Steve was talking about, right, those durable skills.
That's what these are about, right?
So how did it begin?
It was a partnership between WestEd and Scale, for those of you who don't know,
Scale, Stanford Center for Assessment Learning and Equity.
And I'll never forget, I was deputy superintendent at the department, and I got a call from Dr. Darling Hammond,
and she said, Deb, do you think the state would be willing to help us with this project?
And I said, I think so.
I think it would be just great.
And so the state of California was brought into this really incredible piece of work
that had generous funding from Hewlett and Bechtel and the Stuart Foundation.
And we had partner states, so it wasn't just California.
We had California, New Hampshire, and Oregon.
But we certainly had a lot of work going on in California.
And remember, it was so important for the state to bring teachers on board.
We were totally changing the way we were talking about assessment.
And we knew at the time, if we didn't bring our teachers on board,
we'd really suffer the consequences.
And not only would our students not be successful,
but our teachers would be extraordinarily challenged.
So we wanted to make sure that they had the tools that they needed.
So the goals of the project were to build the knowledge of the standards,
because this was back, Common Core was still relatively new,
and these new kinds of assessments, so to build that knowledge.
And to come to kind of a common understanding and a common language
about how we would talk about these assessments.
Strengthen teacher understanding of the instructional shifts, right?
Because there were definite shifts when we moved to Common Core.
And the ways of college and career readiness, how those could be assessed.
It was very different.
And then, probably most importantly, supporting educators in their examination
of student work, particularly performance tasks.
And not only examination, but really thinking about what that student work meant.
I can't tell you, and those of you who maybe participated in some of these trainings,
truly transformational in terms of how teachers looked at student work.
It was really wonderful to look at.
And then here were our independent learning objectives.
So we expected teachers, educators, to learn about performance assessments,
what kind of evidence you were looking for,
how they provided evidence of student learning.
Collaboratively score student work.
So it was about not only this teacher learning,
but they really were getting a common sense of what those expectations were, right?
Making it really transparent about what it meant for a student
to actually be proficient, if you will, on those standards.
And then reviewing student work as a basis for reflecting on
and responding to the evidence of learning that performance tasks can generate.
So it was brand new.
We really were hopeful that people would engage with us.
And fortunately, that absolutely happened.
So what were the benefits of this?
There were many.
Here are a few.
But understanding those assessment literacy concepts sounds simple enough.
But having a common understanding and a common way to talk about this
was really important as we embarked on this new set of assessments and standards.
Really talking about what does it mean to design a performance assessment?
How is that different?
What does it look like?
How can it be used in a classroom?
How can it be used to talk about those instructional shifts?
Also talked about the claims and targets, which are part of a smarter system.
Really talking about what are the demands for students?
What are we asking students to do?
And how is that different from a selected response test?
Certainly, the calibration of student scoring using state-level rubrics.
Remember, Rodriguez, you talked about those protocols, right?
But rubrics are kind of protocols, right?
So really engaging in the rubrics and thinking about what those rubrics are asking our students to do
was very enlightening for our teachers as well.
And then reflection on the instructional implications
that these tasks have for teaching and learning.
So as these teachers are engaging in this professional learning opportunity,
they're thinking about not only about the student work,
but how does that impact what I do as a teacher?
How can I do something differently perhaps
to ensure that my students are able to demonstrate what they know and can do?
This is very reciprocal in nature, right?
This examination of student work.
So it's impactful to both the teacher and the learner, right?
So we did many, many workshops throughout California in particular,
probably more than other states.
But we would always survey our respondents.
And this is kind of indicative of what we always found after our workshops.
I'm confident that I can provide instruction that supports students in performing well.
Now, I would change that question right now if we had to do it over again.
Because I think it's about encouraging students to do well
in terms of what they're learning, right?
It goes beyond showing us what you know and can do on an assessment.
But before the training, about 70 percent, and after the training, 90 percent.
And the training was about two days generally.
And here are a couple of quotes that I think are pretty indicative of how folks responded.
Performance tasks are a better way to authentically assess what students know
about teachers, the ability to understand how they think about mathematics in context.
Again, that reciprocity, this isn't just about gaining knowledge about what our kids can do.
This is helping teachers do a better job, right?
I think that I'm less worried about the testing and it's less of a mystery.
So I'll not project my fears on my students.
We talked about transparency here, right?
Making sure that families know, making sure that students know.
This is certainly helpful in that.
I believe that I can prepare my students and they can be successful.
Because remember, it was kind of a mystery as we started down this journey back in 2014.
And then finally, all K-12 teachers would benefit from experiencing the training.
It underscores how content standards have to be taught and assessed along the learning progression,
informs what students need to be able to know and how to demonstrate what they know.
So as with any good grant, you want it to move forward, right?
So we didn't just stop, nor did the California Department of Education.
So there, nor did lots of county offices of education.
So the grant's purpose was to really train a lot of trainers and get as many people trained as possible.
And what happened, though, was people kind of really liked it.
So you'll see in California, there was this initial cadre of trainers in 2014, 113 people.
And for California at LACO, the L.A. County Office of Education had a particular strong interest.
And they had 265 folks, and then we had 57.
But over the course of the next few years, we've trained over 7,000 in California,
680 Oregon, 200 New Hampshire, 315 in Hawaii.
I have to say that this is a professional learning opportunity that the state of California has used
and is promoting through their professional learning that they offer through their contractor.
So it is offered, or some rendition, some version of it, if you will,
but basically the examination of student work, the calibration of that, the review of state-level rubrics, and so forth.
So you have CASP trainings, LPAC trainings, CASP trainings, and then Oregon, Nevada, and Hawaii have taken it on and moved it forward.
As I said, this L.A. County Office of Education project called the Performance Task Development Project,
they have a bank, if you will, of performance tasks in math and science that they have their teachers write
and then have their teachers score.
And then finally, there's an online course that actually we created, and that is being currently used in Santa Ana Unified.
And here's a quote from Santa Ana.
I found the course was valuable, painted a clear picture of what is expected,
what we should be working on with our students, and provides good examples and resources for teachers to implement in their classrooms.
Again, it's a recurring theme.
Everybody wants to know the information.
We cannot leave teachers out of the equation.
And we have to give them the tools to make sure that they can get into the classroom and teach their students.
And then finally, this is a teacher.
She's actually now an assistant superintendent in Evergreen.
She was one of our trainers.
I just want to let her speak.
Having the time to look at the work sort of independently,
so that that work isn't quite so laborious when you come together, but hugely impactful.
And I think that really needs to be the focus of PLC groups,
is teachers need to be able to come together to talk about student work
and come to consensus on what they agree in terms of how a certain task might be scored.
You know, going through the performance task and having this experience is really powerful,
and being able to look at student work and then thinking about the instructional implications that come from that.
That's the power of where we're headed, I think, in the next several years as far as teaching goes.
We've realized that teachers don't teach curriculum, they teach students.
And this performance task project really respects them in that way,
because it's not taking a program and teaching from it, turning page by page,
but it's empowering teachers to know how they can best support their students and their growth
and learning together within the system.
I couldn't have said it better.
And again, if you think back to what we were charged with in terms of the law,
that's what that teacher just expressed, that this really helps her support teaching and learning.
This is for future, but here are a couple of three websites
that really focus on performance tasks and hand scoring and so forth.
The department's put up an asynchronous hand scoring module that is available to all districts.
We have an understanding proficiency website, and there's a brief about how performance tasks are working in Oregon.
And if anyone needs information, there you go.
And with that, I will hand it back to Dr. Darlene Hammond.
Well, thank you. And let's see if there's some questions for Deb.
Let me just note that because of this practice, we actually required in our contract with ETS
that California teachers score the performance tasks.
But we have not gotten to a place where we have a systematic way to ensure that all teachers get that kind of experience.
So, you know, we got down that path and saw the value and do engage with that.
Other questions for Deb?
All right. I guess I think probably people are a little bit maxed out at this point.
And so I think what we'll do is take a break, take about 10 minutes and come back.
And then we have work to do. See you at 315.
Encouraging everyone to find a seat. Thank you.
All right.
So that was a lot to take in and we want to do some processing of all of that information,
some thinking about what we heard and what we resonated with, et cetera.
I did want to just point out that there's a lot and you sort of heard references.
There's a lot of activity in California already, but we have not like pulled it together into a system, so to speak.
So you heard Steve Pruitt talk about L.A. County Office of Education and San Diego County Office of Education,
which have Performance Task Bank and Math and Science and work in San Francisco.
Also around that, there's an NGSS collaborative that's been doing that work.
When Deb was at Weston, she was facilitating some of the work of those collaboratives.
We have teachers involved in scoring performance assessments on Smarter Balanced.
Again, we don't have a system where everybody gets that experience, but we have opportunities and we've learned from those.
So one of the things for us as we're looking forward is both to get clear about what we think are some important features
of the system we'd like to have and then to get clear about how to make it more systematic
and how to pull that together in the next coming years.
So with that, are there any other questions that people want to ask now that were about the content that we just heard
before we get into our next activity that Deb's going to lead us in? Yeah.
In what we heard, partly based on who presented, but then also in what we read,
it seems like there's a lot of innovative work happening in science right now.
Is that just anecdotal to what we've read or is that where there's a lot of the most innovative stuff happening?
I think one reason there's a lot of innovation happening in science is that, number one,
it was not part of the accountability system that had federal rules attached to it early on,
that it has a federal requirement for once in a great span, but there aren't as many other trappings.
And people got started on science later with NGSS.
And NGSS is very clear about its expectations for performance.
So for all those reasons, it is a place where a lot of people are innovating,
but also there's a lot of interest in coming back around on English language arts and math.
And there are projects, for example, in Louisiana and some other states where they're trying to do curriculum
embedded tasks in English language arts and math that are linked to certain kinds of curriculum that they use.
And there are people who are talking about resonating the, what's the word I'm looking for,
bringing back the writing portfolios that used to be used in Kentucky and Vermont
where there were a few standardized tasks that kids had to do, like an essay,
but they could choose their topic and they could embed it in their experience.
And then there were rubrics to score and they could use that as part of the assessment.
So those things are being talked about.
But there is probably more collaborative state activity in science at the moment.
Any other questions?
So maybe we'll move ahead, Deb, with our sort of our next processing.
I'll bring my facilitator hat back on.
So we've heard a lot today.
And we want you to have a discussion at your table.
This is kind of our, I think we've got, hmm, is it just our time?
What would you like?
Till about 345?
We just said there will be not a half an hour of public comment.
Okay.
And that we could go another half an hour on this activity.
345 for discussion at table?
Yeah.
Okay.
All right.
So you have your question at the table.
It's activity two.
And just let me read it for the public.
Thinking about everything you've heard today, thinking about where we started,
which was what do you like about our current system?
What do you think, how could we make it better?
What are your aspirations?
You heard the three presentations.
What characteristics of the assessment systems and the innovations that you heard
about today do you think might be worth consideration for California's
assessment system?
So think big.
And we'd like you to do this at your table.
There will be report outs at the end of the time.
Okay?
All right.
Yeah.
All right.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
We ready?
Okay.
All right.
Thank you all.
It sounded like there were some really great discussions going on.
And I'm going to ask you all to report out.
And we are starting with this table back here.
And member Escobedo, if you would do the report out.
Sure.
There are four specific areas.
Number one.
Do you want a microphone?
Oh.
Yes.
Yes.
Well, first, we were really enthralled with the statewide test bank system.
But we believe that it should be perhaps on a statewide basis created,
but then have local input from districts,
local teachers to really help inform on how to expand perhaps this test bank.
And this test bank should have delineated tasks that will help teachers with lesson design.
That was one.
Second one, similar to the Beale project,
is to have some type of master trainer model that perhaps can be disseminated by the county offices to teachers,
to help other teachers understand how to create assessments,
but also to have a specific focused protocols to help districts with establishing well-informed,
well-structured PLC models.
Great idea.
And to somehow adhere to some type of design so that teachers have time to collaborate.
Very, very critical.
Also, we believe that having a portfolio for students to have delineated capstone projects,
granting students choice to select a project of their own interest and passion,
is really critical, to have a component where students can really have that choice of what they want to pursue and investigate and analyze.
And finally is to investigate, we're very intrigued with the collaboration project, right?
Because when you think about the world of work,
very rarely do you have jobs where you have a singular person trying to resolve a problem, right?
So if there's some way we can construct and assess one,
where students can work in collaborative groups and work together to solve an issue or problem that's connected to their environment.
Great idea.
Anything else that I missed?
I'm struck by how you're trying to get to your aspirational ideas through this, too.
It's definitely coming forward.
Thank you so much.
Any other comments from that table?
Okay.
All right.
Next, Member Glover-Woods, I believe you are reporting out.
Yes, I am.
And I would like to say I believe that Francisco's table was probably ear-hustling to our table.
I just want to put that out there.
Our thoughts on this question were very similar to what was just shared.
So there are four points I'll lift up for our conversation.
One is how we can have our assessments, particularly those performance-based tasks,
reflect that interdisciplinary integration and to kind of link to Dr. Pruitt's idea of reporting and messaging.
How do we message that in such a way so that teachers feel that that is what they should do?
And that is something that would be helpful to them.
We don't want to say one thing but then advocate for something different that causes confusion and chaos.
Our second, along that idea of student collaboration, is how we can further develop the assessment
to measure those critical thinking skills and engage and value the student collaboration
around those performance tasks with some shared accountability for students as part of our assessment system.
So we'd like to delve a little deeper into that, look at examples,
see if this is something that we can definitely have embedded in the future.
The third is really about relevance to students.
And it speaks to particularly the example we saw, the Hawaii example we saw from our first presentation.
How do we make our assessments and the performance tasks something that is extremely relevant to students in their here and now,
where they are not asking, why do I have to do this, but are wanting to engage in it?
And how can we ensure that the performance tasks once developed to be culturally responsive and relevant are nimble enough
so that over time, if they need to be changed or adapted to continue to be relevant, we as a system are able to do so.
What is relevant in 2023 may not be relevant in 2025.
So how do we create a system that's nimble enough to be able to do that?
And lastly, looking at review of student work, teacher review of student work,
how might we be able to systematize that in such a way that we have more teachers
that are engaging in review of student work and are desiring to engage in the review of student work?
So not a mandate, but something that teachers see that as valuable.
And how to make that practice more widespread across our state, kind of connecting to that field project presentation we had.
And one part of the conversation was about how to engage the university partners in teacher preparation
so that as we're talking about assessment literacy, as we're talking about not just our current system of assessment,
but our future system of assessment, how do those teacher preparation programs prepare our future teachers
to be able to engage in that work as we look at the professional development side for those who are already in the field?
Great points. And again, I'm really seeing that cultural responsiveness
and just the transparency of the assessments and so forth and love the idea about our teacher prep programs.
This table, anyone else want to add?
Just the idea that it's our teachers and everyone who supports teachers.
So as the system, as the learning government comes back to the school site,
what happens in the department meetings and the grade level meetings in an ongoing way is supported by lots of people.
So including them in the learning as well.
This is actually slightly off center of the question.
So you did a beautiful job on the report out on that.
And it's actually more thinking about maybe a common gap in all of the presenters is where are families in all of this.
If we do a really knockout job on the next iteration of assessment
and people still don't understand it who are not in the education sphere,
we're going to still have those polling numbers that I think the first presentation started.
It needs to be digestible for civilians, too.
That's great. Wonderful point.
All right. Anything else? Good. Okay. All right.
And finally, our last table, and I believe member Olken. All right. Great.
This reminds me of our recent confirmation here and going last.
Everything's already been said. Yeah.
So I tried to categorize on the fly the types of things that we came up with into three categories.
I hope you don't mind. So the first is teachers as the key.
We had a lot of comments around the importance of like what we saw, you know,
whether it was the assessment literacy work or the development of performance tasks and sharing of student work and rubrics.
We talked a lot about the importance of time for educators to do this work together,
both at their school site and across schools.
And so part of that getting back to teachers as key was thinking about the places that could happen.
So teacher education, part of induction, ongoing professional development for teachers.
We talked about the role of county offices and also thinking about the ways in which maybe thinking about this work regionally
might be helpful so that teachers feel like it's not such a huge and distant initiative and also so the work really reflects the local community.
I think those are the big things related to teachers as key.
And then the second one was students and their assets.
So we liked the way that we saw examples of tasks that use different modalities and ask students to explain and show what they know in different ways.
Some of the what we saw there were supports built in for students who learn differently and express themselves in different ways.
And so really ensuring that students can share what they know in ways that work for them and that honor their strengths.
We talked a lot about the importance of the work being relevant to students.
Just jump piggybacking on what we heard before, build on what they know and what they care about.
And so the way that performance tasks can allow that to happen in a way that isn't possible in other types of assessment.
And then the third broad category was authentic assessments.
So we appreciated the assessments that were focusing on problem solving and showing learning rather than regurgitation of fact hands on learning and demonstration of mastery.
And we talked a lot about assessments that are embedded into instruction rather than solely summative.
And there was one more thing. Oh, this is just me because I have the microphone.
There was one of the states.
I think it was Kentucky.
They had in this.
I thought of this based on what Ken just said.
They had a very succinct set of what their guiding principles for assessment were.
And I think in terms of being able to convey to lots of different constituents, families, kids, teachers, administrators,
why we're doing what we're doing, something that's simple and high level and sort of values based is probably a good place to start.
OK, other thoughts?
I want to add something.
Thank you, Sharon. That was actually pretty comprehensive of what we discussed.
But I just throughout all the conversations that we had, and it goes back to even my work as a teacher becoming involved in 2014.
And I even mentioned I was part of the bill project and and doing a lot of this professional learning with Smarter Balanced.
The consortium is that building capacity is key.
And some of the work that we've done, even as the CTA in collaboration with Stanford is the Instructional Leadership Corps and teachers leading this work in their schools,
the district in their districts and in communities.
I know a lot of the teachers that did some of the work through this project is doing professional learning with parents and engaging them,
building partner partnering and building bridges with them and having parents going through the scoring through the assessments and having them understand how to best support their children.
And so I think this goes back to even foundationally what we've been talking about with community schools and how we want to incorporate all stakeholders.
And I think this work goes deeper when we do that and when we give teachers the power to lead, I think it can really move mountains.
And I think going back to member Petillo-Brownson, that whole aspect around family, so important.
And, you know, thinking about some of these courses, if we'd expanded to families, maybe we wouldn't have those public opinion polls that we currently have.
Yeah, sure.
On a couple of the details associated with one of the things we talked about was the importance of a task bank that would include rich meaningful tasks that engage students in relevant ways and also include student work and rubrics,
which is related to how you involve both the teachers and the parents and families that you have things that can then be part of the instructional process.
Both for assessment purposes, summative assessment purposes, but also for teaching and learning purposes and for those sharing purposes.
The other thing we talked about as we were talking about how teachers need to be meaningfully engaged in every part of this, including the scoring.
I was reflecting on the fact that in New York, you know, they use the Regents exams, which are designed and scored by teachers every year for hundreds of years for a long time.
It actually is part of the sort of British Blue Book system, which you have translated to lots of places.
But there's two professional development days every year for teachers to, you know, score the students work.
The tasks are not secret. They know what they're teaching toward and they know, you know, what the kids will need to do.
And then they're part of that process.
So just kind of elaborating on the field experience, there are systems that have figured out how to make that possible.
And so we talked a little bit about that, too, really just ingrained into the process and to classrooms and so forth.
I think we need to get there. Other thoughts at this table.
We good. All right.
I think I'm going to turn it back over to you.
Is that correct? Yes.
And thank you all. You've been great participants.
So we have learned a lot and we're going to all be thinking about this more.
And this will not be the last chance we have to talk about it together.
And I'm looking forward.
We will be hearing more also from our assessment partners in the state about ideas that are surfacing for how we might move forward in science
and then also in English language arts and math.
One of the things that I've been thinking about as we've been talking today is how we conceptualize a system.
You know, we have lots of innovative components as we do on most things in California here and there.
And so I think we should all kind of keep that in mind that we're going to be thinking about what is plausible in that sense.
And how do we link up supports for the teaching and learning process to the way in which assessments unfold?
One of the things that I think is really interesting and what we saw today was the fact that in, for example, Massachusetts, they have these tasks.
They're getting a bank of tests. They're doing classroom tasks.
But the kinds of thing they're doing there are also appearing again on the summit of assessment.
So they're linking across the domains in ways that are purposeful and deliberative.
So I think that that's one part of our process and the others continue to think about these supports.
And it was really wonderful, Deb. Thank you so much for facilitating.
I also want to just take this moment to thank all the staff who are behind the curtain.
We can't see them, but we want to thank them.
When we envisioned having a little retreat, you know, I had no idea how complicated it would be to do a multimedia production, which is what we've done today.
And really, that was made possible by many, many people who will at some point pop out from behind the curtain and you can take them to their face.
I think at this point, we need to go ahead and open the phone line for public comment.
So I'm going to ask whoever does that to open the phone line. And there we have it.
What we see in our board members, members of the public who wish to provide comments on this item can do so by calling the telephone number and using the access code provided on the slide that is shown now.
We encourage you to please state your name and affiliation for the record.
Please remember to turn down the speaker volume of your computers if you're following the live feed.
Speakers will be limited to one minute each and we will go to public comment here in the boardroom first if there is any.
Anybody wants to come to the microphone and then we will take public comments on the phone if there is any there.
Hi, everybody. Manuel Bonrostro with Californians Together and I just want to thank Board President Linda Darling-Hammond and all of you for having this important conversation about assessments.
A few things that stood out to us that we highly support are making sure that assessments are culturally relevant.
The performance based assessments are critical.
Love the suggestion about making sure that students have options and choice about assessments that they select.
Definitely support the considerations for families and making sure that families understand assessments.
One piece that we do suggest thinking a little bit about that we didn't hear as much today is how do we leverage the home languages of students as they do some of these assessments to make sure that that asset that they come with can be used so they can display the knowledge that they possess and that they come to school with.
So thanks again and we look forward to more conversations about this.
It's really a positive step for California to see all the wonderful work that we might do in the future.
Thank you.
Good afternoon, everybody.
Shelly Spiegel-Coleman from Californians Together.
The first thing I want to say, it's so nice to see you in person.
We've been watching you for over two years on the screen, right?
So this is just lovely.
We both have been chatting while you've been chatting, and we're so excited about this new direction or the work, the potential of the work that we have in front of us.
And there is one piece that we think would be really great to think about, and that is that right now I know the department has a contract with ETS to develop the interim assessments for LPAC.
It would be really good if this, what you talked about today, was part of that development because the LPAC itself is somewhat of a performance assessment, right?
And if the interims were that way, too, it would be terrific.
So we'd love you to consider that.
And again, congratulations and thanks so much for having this valuable, valuable conversation.
Maybe all the comments in the room.
Is that right?
Okay, so is there any public comment by phone?
We do not have any callers in the queue.
All right.
This would have been hard to watch on the live stream.
If anybody did it, I would give them a lot of props for that.
I'm going to ask member Roscoe-Gonzalez if she would like to make some final remarks as our assessment liaison.
Great productive conversation.
As you know, with improductive workgroups, students learn best, and I think it goes the same for us.
I think we need to take into account our diverse student backgrounds and social and cultural experiences to level the playing field.
And I hear about how important it is to include leveraging the students' home language also when it comes to creating these assessments.
I know personally since English is a second language for myself too, so I know the importance of highlighting that too.
But I'm excited to have teacher voice, to have teachers being part of the conversation,
and to be the key component when it comes to creating these assessments and to building capacity throughout our state because we're the ones in the classroom.
We're the ones that know the children firsthand and know the different learning modalities and how important it is for us,
our differentiation in the classroom to target the needs of every single student.
So I think that was the best takeaway that teachers are the center of this work as we embark in anything new or continue to as we progress.
So thank you.
And after this long day, I'm just going to bless this gathering
and send everyone off to their next pursuits and to dinner and say that we will see you at 830 in the morning tomorrow.
And it's wonderful to see everyone in person.
Yay.
